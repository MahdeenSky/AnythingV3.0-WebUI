{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfKvWAVnz8OB"
      },
      "source": [
        "<fieldset>\n",
        "    <legend>\n",
        "    <h2><b>How to use?</b></h2>\n",
        "    </legend>\n",
        "    \n",
        "1. Edit the settings by checking the checkbox to your liking\n",
        "2. Run the cell by clicking ‚ñ∂Ô∏è button, from top to bottom\n",
        "3. After running the start webui cell, wait for few minutes until it says \"Connected\" then click on the link above it. (not 127.0.0.1)\n",
        "\n",
        "</fieldset>\n",
        "\n",
        "**‚ö†Ô∏è DO NOT USE \"RUN ALL\", I REPEAT, DO NOT USE \"RUN ALL\" ‚ö†Ô∏è** \n",
        "<br>\n",
        "\n",
        "If something is broken:\n",
        "- Do raise an issue on github."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DJ7Yzy8Asu3Y"
      },
      "outputs": [],
      "source": [
        "#@title # **üëá Test your GPU runtime**\n",
        "import os\n",
        "from subprocess import getoutput\n",
        "import time\n",
        "\n",
        "def increase_font():\n",
        "  from IPython.display import Javascript\n",
        "  display(Javascript('''\n",
        "  for (rule of document.styleSheets[0].cssRules){\n",
        "    if (rule.selectorText=='body') {\n",
        "      rule.style.fontSize = '45px'\n",
        "      rule.style.fontWeight = '600'\n",
        "      break\n",
        "    }\n",
        "  }\n",
        "  '''))\n",
        "\n",
        "output = getoutput('nvidia-smi --query-gpu=gpu_name --format=csv')\n",
        "increase_font()\n",
        "if \"name\" in output:\n",
        "  print('\u001b[32mGPU Connected! Currently using', output[5:], \"‚úÖ\") \n",
        "  print('You may continue.')\n",
        "else:\n",
        "  print(\"\\033[91mNo GPU accelerator is connected. \\nPlease connect to a GPU Runtime\")\n",
        "print(\"\\033[0m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBbcB4vwj_jm",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **üëá Run Collab to generate WebUI Link for AnythingV3**\n",
        "\n",
        "%cd /content\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "from subprocess import getoutput\n",
        "from IPython.utils import capture\n",
        "\n",
        "try:\n",
        "  start_colab\n",
        "except:\n",
        "  start_colab = int(time.time())\n",
        "\n",
        "run_in_gdrive = False\n",
        "root_dir = \"/content\"\n",
        "if run_in_gdrive:\n",
        "  if not os.path.exists('/content/gdrive'):\n",
        "    drive.mount('/content/gdrive')\n",
        "  !mkdir -p {'/content/gdrive/MyDrive/WebUI'}\n",
        "  root_dir = \"/content/gdrive/MyDrive/WebUI\"\n",
        "\n",
        "\n",
        "def rm_drive_path(path):\n",
        "  if run_in_gdrive:\n",
        "    if os.path.exists(root_dir+\"/stable-diffusion-webui/\"+path):\n",
        "      !rm -rf {root_dir}/stable-diffusion-webui/{path}\n",
        "\n",
        "if os.path.exists(root_dir+\"/stable-diffusion-webui\"):\n",
        "  %cd {root_dir}/stable-diffusion-webui/\n",
        "  !git checkout master\n",
        "  !git pull\n",
        "else:\n",
        "  !git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui {root_dir}/stable-diffusion-webui\n",
        "  !mkdir -p {root_dir}/stable-diffusion-webui/models/hypernetworks\n",
        "  %cd {root_dir}/stable-diffusion-webui/\n",
        "\n",
        "commit_hash = \"\" \n",
        "if commit_hash:\n",
        "  with capture.capture_output() as cap:\n",
        "    !git config --global user.email \"you@example.com\"\n",
        "    !git config --global user.name \"Your Name\"\n",
        "    !git stash\n",
        "    !git reset --hard {commit_hash}\n",
        "    !git stash pop\n",
        "\n",
        "custom_config = True \n",
        "if custom_config:\n",
        "  !wget -q -O styles.csv https://raw.githubusercontent.com/NoCrypt/webui-settings/main/styles.csv\n",
        "  !wget -q -O config.json https://raw.githubusercontent.com/NoCrypt/webui-settings/main/config.json\n",
        "  !wget -q -O ui-config.json https://raw.githubusercontent.com/NoCrypt/webui-settings/main/ui-config.json\n",
        "  !wget -q -O user.css https://raw.githubusercontent.com/NoCrypt/webui-settings/main/user.css\n",
        "\n",
        "output_to_drive = True \n",
        "if output_to_drive:\n",
        "  if not os.path.exists('/content/gdrive'):\n",
        "    drive.mount('/content/gdrive')\n",
        "  !sed -i 's@\"outdir_txt2img_samples\": \"outputs/txt2img-images\"@\"outdir_txt2img_samples\": \"/content/gdrive/MyDrive/WebUI/outputs/txt2img-images\"@' {root_dir}/stable-diffusion-webui/config.json\n",
        "  !sed -i 's@\"outdir_img2img_samples\": \"outputs/img2img-images\"@\"outdir_img2img_samples\": \"/content/gdrive/MyDrive/WebUI/outputs/img2img-images\"@' {root_dir}/stable-diffusion-webui/config.json\n",
        "  !sed -i 's@\"outdir_extras_samples\": \"outputs/extras-images\"@\"outdir_extras_samples\": \"/content/gdrive/MyDrive/WebUI/outputs/extras-images\"@' {root_dir}/stable-diffusion-webui/config.json\n",
        "  !sed -i 's@\"outdir_txt2img_grids\": \"outputs/txt2img-grids\"@\"outdir_txt2img_grids\": \"/content/gdrive/MyDrive/WebUI/outputs/txt2img-grids\"@' {root_dir}/stable-diffusion-webui/config.json\n",
        "  !sed -i 's@\"outdir_img2img_grids\": \"outputs/img2img-grids\"@\"outdir_img2img_grids\": \"/content/gdrive/MyDrive/WebUI/outputs/img2img-grids\"@' {root_dir}/stable-diffusion-webui/config.json\n",
        "  !sed -i 's@\"outdir_save\": \"log/images\"@\"outdir_save\": \"/content/gdrive/MyDrive/WebUI/outputs/log/images\"@' {root_dir}/stable-diffusion-webui/config.json\n",
        "\n",
        "\n",
        "# Add booru tag suggestion by DominikDoom\n",
        "add_prompt_suggestion = True \n",
        "if add_prompt_suggestion:\n",
        "  rm_drive_path('extensions/a1111-sd-webui-tagcomplete')\n",
        "  %cd {root_dir}/stable-diffusion-webui\n",
        "  !git clone https://github.com/DominikDoom/a1111-sd-webui-tagcomplete extensions/a1111-sd-webui-tagcomplete\n",
        "\n",
        "# Add novelai_converter\n",
        "add_novelai_converter = True \n",
        "if add_novelai_converter:\n",
        "  rm_drive_path('extensions/novelai-2-local-prompt')\n",
        "  !git clone https://github.com/animerl/novelai-2-local-prompt.git extensions/novelai-2-local-prompt\n",
        "\n",
        "# Add UmiAI\n",
        "add_UmiAI = True\n",
        "if add_UmiAI:\n",
        "  rm_drive_path('extensions/UnivAICharGen')\n",
        "  !git clone https://github.com/Klokinator/UnivAICharGen.git extensions/UnivAICharGen\n",
        "\n",
        "# Add Image History\n",
        "add_image_history = True\n",
        "if add_image_history:\n",
        "  rm_drive_path('extensions/images-browser')\n",
        "  !git clone https://github.com/yfszzx/stable-diffusion-webui-images-browser extensions/images-browser\n",
        "\n",
        "# Add Dynamic Prompt\n",
        "add_dynamic_prompting = False \n",
        "if add_dynamic_prompting:\n",
        "  rm_drive_path('extensions/dynamic-prompts')\n",
        "  !git clone https://github.com/adieyal/sd-dynamic-prompting/ extensions/dynamic-prompts\n",
        "\n",
        "# Add Wildcards\n",
        "add_wildcards = False \n",
        "if add_wildcards:\n",
        "  rm_drive_path('extensions/wildcards')\n",
        "  !git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui-wildcards extensions/wildcards\n",
        "\n",
        "\n",
        "pr3962_dynamic_thresholding = False \n",
        "using_experimental = False\n",
        "\n",
        "if pr3962_dynamic_thresholding:\n",
        "  !git config --global user.email \"why@not.gg\"\n",
        "  !git config --global user.name \"idk how2use git\"\n",
        "  !git checkout -b experimental_thingy\n",
        "  using_experimental = True\n",
        "\n",
        "#https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/3962\n",
        "if pr3962_dynamic_thresholding:\n",
        "  !git fetch origin pull/3962/head:pr3962\n",
        "  !git merge --no-commit pr3962\n",
        "\n",
        "\n",
        "print(\"\\033[0m\")\n",
        "faster_dep_install = False \n",
        "if faster_dep_install:\n",
        "  %cd /content/\n",
        "  for i in range(1,7):\n",
        "      !wget -q \"https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/Dependencies_AUT.{i}\"\n",
        "      !mv \"Dependencies_AUT.{i}\" \"Dependencies_AUT.7z.00{i}\"\n",
        "  !7z x Dependencies_AUT.7z.001\n",
        "  time.sleep(2)\n",
        "  !cp -r /content/usr/local/lib/python3.8/dist-packages /usr/local/lib/python3.8/\n",
        "  !rm -r /content/usr\n",
        "  for i in range(1,7):\n",
        "      !rm \"Dependencies_AUT.7z.00{i}\"\n",
        "  !pip install -U -q pillow\n",
        "  !pip uninstall -y -q gradio\n",
        "  using_experimental = True\n",
        "\n",
        "\n",
        "high_concurrency_count = False \n",
        "import mmap\n",
        "# /content/stable-diffusion-webui/webui.py\n",
        "if os.path.exists(root_dir+\"/stable-diffusion-webui/webui.py\"):\n",
        "  with open(root_dir+\"/stable-diffusion-webui/webui.py\", 'rb', 0) as file:\n",
        "    s = mmap.mmap(file.fileno(), 0, access=mmap.ACCESS_READ)\n",
        "    if s.find(b'concurrency_count') != -1:\n",
        "      if not high_concurrency_count:\n",
        "        !sed -i 's@ui.create_ui();shared.demo.queue(concurrency_count=999999,status_update_rate=0.1).*@ui.create_ui()@' {root_dir}/stable-diffusion-webui/webui.py\n",
        "    elif high_concurrency_count:\n",
        "      !sed -i 's@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count=999999,status_update_rate=0.1)@' {root_dir}/stable-diffusion-webui/webui.py\n",
        "      using_experimental = True\n",
        "  \n",
        "large_model_compatibility = False \n",
        "if large_model_compatibility:\n",
        "  !sed -i 's@cmd_opts.lowram else \\\"cpu\\\"@cmd_opts.lowram else \\\"cuda\\\"@' {root_dir}/stable-diffusion-webui/modules/shared.py\n",
        "  using_experimental = True\n",
        "else:\n",
        "  !sed -i 's@cmd_opts.lowram else \\\"cuda\\\"@cmd_opts.lowram else \\\"cpu\\\"@' {root_dir}/stable-diffusion-webui/modules/shared.py\n",
        "\n",
        "if using_experimental:\n",
        "  print(\"\\033[93m‚ö†Ô∏è WARNING: EXPERIMENTAL OPTION IS ACTIVE! ‚ö†Ô∏è\\nDO NOT REPORT IF ANYTHING IS BROKEN!\\nThe output will be yellow during startup to mark this\\nTo Remove, Rerun install dep without experimental, but restart runtime is highly recommended\\n\")\n",
        "  \n",
        "%cd {root_dir}/stable-diffusion-webui\n",
        "!COMMANDLINE_ARGS=\"--exit\" REQS_FILE=\"requirements.txt\" python launch.py\n",
        "\n",
        "# SECOND STAGE (INSTALLING)\n",
        "try:\n",
        "  start_colab\n",
        "except:\n",
        "  sys.exit(\"ü´§ YOU HAVEN'T RUN INSTALL DEPENDENCIES CELL\")\n",
        "%cd {root_dir}/stable-diffusion-webui/models/Stable-diffusion/\n",
        "!pip install -q -U gdown\n",
        "\n",
        "\n",
        "def install_aria():\n",
        "  if not os.path.exists('/usr/bin/aria2c'):\n",
        "    !apt -qq install -y aria2\n",
        "\n",
        "def custom_hf_model(url, checkpoint_name=\"\"):\n",
        "  install_aria()\n",
        "  if checkpoint_name:\n",
        "    # !wget -c --show-progress --header={user_header} {url} -O {root_dir}/stable-diffusion-webui/models/Stable-diffusion/{checkpoint_name}.ckpt\n",
        "    !aria2c  --summary-interval=10 -c --header={user_header} -x 10 -k 1M -s 10 -d {root_dir}/stable-diffusion-webui/models/Stable-diffusion -o {checkpoint_name} {url}\n",
        "  else:\n",
        "    !aria2c  --summary-interval=10 -c --header={user_header} -x 10 -k 1M -s 10 -d {root_dir}/stable-diffusion-webui/models/Stable-diffusion/ {url}\n",
        "\n",
        "custom_hf_token = \"\" \n",
        "default_token = \"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\"\n",
        "user_token = custom_hf_token if custom_hf_token else default_token\n",
        "user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "  \n",
        "Anything_safetensors = True\n",
        "if Anything_safetensors:\n",
        "  custom_hf_model(\"https://huggingface.co/NoCrypt/safetensor_models/resolve/main/Anything-V3.0-pruned-fp32.safetensors\", \"Anything-V3.0-pruned-fp32.safetensors\")\n",
        "  custom_hf_model(\"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0.vae.pt\", \"Anything-V3.0-pruned-fp32.vae.pt\")\n",
        "\n",
        "# THIRD STAGE (Running WEBUI)\n",
        "server = \"gradio\" \n",
        "%cd /content\n",
        "!sed -i '/is_colab = /c\\            self.is_colab = False' /usr/local/lib/python3.8/dist-packages/gradio/blocks.py\n",
        "param = \"\"\n",
        "gradio_username = \"\"\n",
        "gradio_password = \"\"\n",
        "if gradio_username and gradio_password:\n",
        "  param += \" --gradio-auth {}:{}\".format(gradio_username, gradio_password)\n",
        "\n",
        "if server == \"gradio\":\n",
        "  param+=\" --share\"\n",
        "  !sed -i '/self.server_name = /c\\            self.server_name = server_name' /usr/local/lib/python3.8/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/self.server_port = /c\\            self.server_port = server_port' /usr/local/lib/python3.8/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/    else \"http/c\\                else \"http\"' /usr/local/lib/python3.8/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/\"PUBLIC_SHARE_TRUE\":/c\\    \"PUBLIC_SHARE_TRUE\": \"\u001b[32mConnected\u001b[0m\",' /usr/local/lib/python3.8/dist-packages/gradio/strings.py\n",
        "\n",
        "elif server == \"localtunnel\":\n",
        "  if not os.path.exists('/tools/node/bin/lt'):\n",
        "    !npm install -g localtunnel\n",
        "  !nohup lt --port 7860 > srv.txt 2>&1 &\n",
        "  time.sleep(2)\n",
        "  !grep -o 'https[^ ]*' /content/srv.txt >srvr.txt\n",
        "  time.sleep(2)\n",
        "  srv= getoutput('cat /content/srvr.txt')\n",
        "  !sed -i '/self.server_name = /c\\            self.server_name = \"{srv[8:]}\"' /usr/local/lib/python3.8/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/self.server_port = /c\\            self.server_port = 443' /usr/local/lib/python3.8/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/    else \"http/c\\                else \"https\"' /usr/local/lib/python3.8/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/\"PUBLIC_SHARE_TRUE\":/c\\    \"PUBLIC_SHARE_TRUE\": \"\u001b[32mConnected\u001b[0m\",' /usr/local/lib/python3.8/dist-packages/gradio/strings.py\n",
        "  !rm /content/srv.txt\n",
        "  !rm /content/srvr.txt\n",
        "\n",
        "elif server == \"cloudflared\":\n",
        "  if not os.path.exists('/usr/bin/cloudflared'):\n",
        "    !curl -Lo /usr/bin/cloudflared https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 && chmod +x /usr/bin/cloudflared\n",
        "  while True:\n",
        "    !cloudflared tunnel --url localhost:7860 > clf.txt 2>&1 &\n",
        "    time.sleep(9)\n",
        "    !grep -m2 -o 'https[^ ]*' /content/clf.txt | tail -n1 > clfr.txt\n",
        "    srvs = getoutput('cat /content/clf.txt')\n",
        "    if \"has been created\" in srvs:\n",
        "      break\n",
        "    !rm /content/clf.txt\n",
        "    !rm /content/clfr.txt\n",
        "  srv= getoutput('cat /content/clfr.txt')\n",
        "  !sed -i '/self.server_name = /c\\            self.server_name = \"{srv[8:]}\"' /usr/local/lib/python3.8/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/self.server_port = /c\\            self.server_port = 443' /usr/local/lib/python3.8/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/    else \"http/c\\                else \"https\"' /usr/local/lib/python3.8/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/\"PUBLIC_SHARE_TRUE\":/c\\    \"PUBLIC_SHARE_TRUE\": \"\u001b[32mConnected\u001b[0m\",' /usr/local/lib/python3.8/dist-packages/gradio/strings.py\n",
        "  !rm /content/clf.txt\n",
        "  !rm /content/clfr.txt\n",
        "\n",
        "elif server == \"bore\":\n",
        "  if not os.path.exists('/usr/bin/bore'):\n",
        "    !curl -Ls https://github.com/ekzhang/bore/releases/download/v0.4.0/bore-v0.4.0-x86_64-unknown-linux-musl.tar.gz | tar zx -C /usr/bin\n",
        "  !bore local 7860 --to bore.pub > bore.txt 2>&1 &\n",
        "  time.sleep(2)\n",
        "  !grep -o -m1 'bore.pub:[^ ]*' /content/bore.txt > boreport.txt\n",
        "  boreport = getoutput('cat /content/boreport.txt')\n",
        "  !sed -i '/self.server_name = /c\\            self.server_name = \"bore.pub\"' /usr/local/lib/python3.8/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/self.server_port = /c\\            self.server_port = {boreport[9:]}' /usr/local/lib/python3.8/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/    else \"http/c\\                else \"http\"' /usr/local/lib/python3.8/dist-packages/gradio/blocks.py\n",
        "  !sed -i '/\"PUBLIC_SHARE_TRUE\":/c\\    \"PUBLIC_SHARE_TRUE\": \"\u001b[32mConnected, using HTTP only!!\u001b[0m\",' /usr/local/lib/python3.8/dist-packages/gradio/strings.py\n",
        "  !rm /content/bore.txt\n",
        "  !rm /content/boreport.txt\n",
        "\n",
        "# Model\n",
        "first_load_model = \"auto\" \n",
        "param += \" --ckpt \"+root_dir+\"/stable-diffusion-webui/models/Stable-diffusion/\"+first_load_model if first_load_model!=\"auto\" else \"\"\n",
        "\n",
        "xformers = True \n",
        "if xformers:\n",
        "  s = getoutput('nvidia-smi --query-gpu=gpu_name --format=csv')\n",
        "\n",
        "  if os.path.exists('/usr/local/lib/python3.8/dist-packages/xformers'):\n",
        "\n",
        "    if \"A100\" in s:\n",
        "      !wget -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/A100\n",
        "      %cd /usr/local/lib/python3.8/dist-packages/xformers\n",
        "      !7z x -y /content/A100\n",
        "      !rm /content/A100\n",
        "    if not (\"T4\" in s or \"A100\" in s):\n",
        "      print(\"[XFORMERS] GPU isn't supported.\")\n",
        "      !pip uninstall -q -y xformers\n",
        "      xformers = False\n",
        "  else:\n",
        "    if 'T4' in s:\n",
        "      !pip install -q https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.15/xformers-0.0.15.dev0+189828c.d20221207-cp38-cp38-linux_x86_64.whl\n",
        "    elif \"A100\" in s:\n",
        "      !wget -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/A100\n",
        "      %cd /usr/local/lib/python3.8/dist-packages/xformers\n",
        "      !7z x -y /content/A100\n",
        "      !rm /content/A100\n",
        "    else:\n",
        "      print(\"[XFORMERS] GPU isn't supported.\")\n",
        "      xformers = False\n",
        "param += \" --xformers\" if xformers else \"\"\n",
        "s=\"\" \n",
        "\n",
        "# Disable safe unpickle\n",
        "disable_safe_unpickle = True \n",
        "param += \" --disable-safe-unpickle\" if disable_safe_unpickle else \"\"\n",
        "\n",
        "# Medvram\n",
        "medvram = False \n",
        "param += \" --medvram\" if medvram else \"\"\n",
        "\n",
        "# precision_full_no_half\n",
        "precision_full_no_half = False \n",
        "param += \" --precision full --no-half\" if precision_full_no_half else \"\"\n",
        "\n",
        "# API\n",
        "api = False \n",
        "paint_hua_support = False \n",
        "param += \" --api --cors-allow-origins=https://www.painthua.com\" if paint_hua_support else \" --api\" if api else \"\"\n",
        "\n",
        "# No Half VAE\n",
        "no_half_vae = True \n",
        "param += \" --no-half-vae\" if no_half_vae else \"\"\n",
        "\n",
        "img2img_color_sketch = False \n",
        "param+=\" --gradio-img2img-tool color-sketch\" if img2img_color_sketch else \"\"\n",
        "\n",
        "inpaint_color_sketch = False \n",
        "param+=\" --gradio-inpaint-tool color-sketch\" if inpaint_color_sketch else \"\"\n",
        "\n",
        "dark_theme = True \n",
        "param+=\" --theme dark\" if dark_theme else \" --theme light\"\n",
        "\n",
        "custom_arguments = \"\" \n",
        "param += \" \" + custom_arguments if custom_arguments else \"\"\n",
        "\n",
        "ngrok_token = \"\" \n",
        "ngrok_region = \"ap\" \n",
        "\n",
        "save_and_use_token_and_region_in_drive = True \n",
        "if server == \"ngrok\":\n",
        "  if save_and_use_token_and_region_in_drive:\n",
        "    if not os.path.exists('/content/gdrive'):\n",
        "      drive.mount('/content/gdrive')\n",
        "    if ngrok_token:\n",
        "      if not os.path.exists(\"/content/gdrive/MyDrive/WebUI/ngrokToken.txt\"):\n",
        "        !mkdir -p /content/gdrive/MyDrive/WebUI/\n",
        "        !touch /content/gdrive/MyDrive/WebUI/ngrokToken.txt\n",
        "      f = open(\"/content/gdrive/MyDrive/WebUI/ngrokToken.txt\", \"w+\")\n",
        "      f.write(ngrok_token+\",\"+ngrok_region)\n",
        "      f.close()\n",
        "    elif os.path.exists('/content/gdrive/MyDrive/WebUI/ngrokToken.txt'):\n",
        "      ngrok_token,ngrok_region = getoutput(\"cat /content/gdrive/MyDrive/WebUI/ngrokToken.txt\").split(\",\",2)\n",
        "    else:\n",
        "      print(\"warning: ngrok token not detected\")\n",
        "  param+=' --ngrok '+ngrok_token+' --ngrok-region '+ngrok_region\n",
        "\n",
        "\n",
        "%cd {root_dir}/stable-diffusion-webui\n",
        "def colab_time():\n",
        "  import time\n",
        "  from datetime import timedelta\n",
        "  time_since_start = timedelta(seconds=time.time()-start_colab)\n",
        "  if time_since_start.seconds / 60 < 45:\n",
        "    print(\"\\033[92m\")\n",
        "  elif time_since_start.seconds / 60 > 80:\n",
        "    print(\"\\033[91m\")\n",
        "  else:\n",
        "    print(\"\\033[93m\")\n",
        "  print(\"\\n\\n=======================================================\\n\\n\")\n",
        "  print(\"‚åö You've been running this colab for:\",\"%02d:%02d:%02d\" % (time_since_start.seconds / 3600, (time_since_start.seconds / 60) % 60, time_since_start.seconds % 60),\" ‚åö\")\n",
        "  print(\"\\n\\n=======================================================\\n\\n\\033[0m\")\n",
        "\n",
        "colab_time()\n",
        "!COMMANDLINE_ARGS=\"\" REQS_FILE=\"requirements.txt\" python launch.py $param\n",
        "colab_time()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^"
      ],
      "metadata": {
        "id": "Qv3h2vT-vivK"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "c6B9e8Zxoj1N"
      ],
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}